---
title: 现在的国产AI都这么好用了？
description: 
keywords: 
categories: 
tags: 
date: 2025-02-09
headimg: 
author: tbs
---

{% gallery stretch::6::two %}
{% endgallery %}
一、公司背景
DeepSeek（深度求索）由幻方量化于2023年7月创立，致力于通用人工智能（AGI）领域的研究和开发。幻方量化在量化交易领域积累了丰富的技术经验，DeepSeek的成立标志着其向人工智能领域的战略延伸。


二、技术特点

• 混合专家模型（MoE）

• DeepSeek采用了MoE架构，通过训练多个专家模型，并根据输入数据的特征动态选择最合适的专家模型进行处理，从而实现对复杂任务的高效处理。

• DeepSeek-V3模型通过MoE架构优化，仅用2.664M H800 GPU小时就完成了预训练，展现出极高的训练效率。


• 多头潜在注意力机制（MLA）

• MLA技术显著降低了模型推理成本，通过减少对KV矩阵的重复计算，提高了模型的运行效率。

• DeepSeek-V3在推理效率上进行了优化，使其能够高效处理长上下文任务，支持最长128K输入序列。


• 多模态融合

• DeepSeek通过多模态模型架构（如MHLA和MoE）和全模态对齐框架（Align-Anything），实现了文本、图像、音频等多种模态数据的高效处理。

• 在多模态任务中，DeepSeek表现出色，例如在ARC-Challenge测试中，多模态版本的成绩从单模态的21.4提升到了40.5。


• 低成本训练

• DeepSeek的训练成本极低，例如DeepSeek-R1的训练成本仅为557.6万美元，而GPT-4的训练成本则高达数十亿美元。

• DeepSeek-V3的完整训练过程（包括预训练、上下文长度扩展和后训练）仅需2.788M H800 GPU小时。


• 开源生态

• DeepSeek采用开源策略，发布了多个开源模型，如DeepSeek-R1和DeepSeek-V3。这种开放性不仅降低了技术门槛，还促进了全球开发者社区的参与和创新。


三、主要模型

• DeepSeek-V3

• 参数量达到6710亿，训练成本仅557.6万美元。

• 在多项基准测试中表现优异，例如在教育类基准测试中，DeepSeek-V3在MMLU、MMLU-Pro和GPQA测试中分别获得了88.5、75.9和59.1的优异成绩。

• 在中文事实知识测试中超越了GPT-4o和Claude-Sonnet-3.5，展现出其在中文领域的特殊优势。


• DeepSeek-R1

• 是一款推理模型，以极低的成本实现了与OpenAI的o1同级别的性能。

• 在智能度、匹配度方面与GPT-4o-Mini“旗鼓相当”，并在正确回复一致度方面高于GPT-4o-Mini。


四、应用场景

• 智能客服对话系统

• 能够快速响应用户问题，提供精准的解答。


• 代码自动补全工具

• 帮助开发者提高编程效率。


• 知识库问答助手

• 快速检索知识库中的信息，为用户提供答案。


• 数据分析报告生成

• 根据输入的数据生成分析报告。


• 智能金融领域

• 可以通过分析海量金融数据，提供投资建议和风险评估。


• 医疗健康领域

• 有助于辅助诊断、药物研发等，提高医疗水平。


五、影响与未来展望

• 重塑AI行业

• DeepSeek的出现打破了原有的格局，缩小了中美之间的科技差距，促使闭源巨头重新审视自身策略。


• 催生新生态

• 开源模式促进了开发者之间的协作和创新，形成了新的技术生态。


• 推动AI普及

• 低成本的模型训练和运行成本有利于AI在整个社会的普及，加速了人工智能技术在更多场景的应用。


• 激励技术创新

• DeepSeek的创新技术将激励更多科研团队和企业投入研发，推动整个人工智能技术的进步。


• 未来发展方向

• 多模态融合：进一步探索自然语言处理、计算机视觉等技术的深度结合。

• 优化模型：提高对复杂问题的理解和解决能力，在强化学习方面持续创新。

• 应用拓展：在智能家居、智能交通、文化创意等领域实现更广泛的应用。

DeepSeek凭借其技术创新、低成本高性能以及开源生态等优势，正在引领AI行业的发展，并为未来的技术进步和应用拓展奠定了坚实的基础。
